BIC_variables = which.min(reg.summary$bic)
points(9,reg.summary$bic[9],col="red",cex=2,pch=20)
plot(regfit.full,scale="bic")
plot(regfit.full, scale ='Cp')
CP_variables
BIC_variables
coef(regfit.full,12)
CP_model = lm(Apps~Private+Accept+Enroll+Top10perc+Top25perc+F.Undergrad+P.Undergrad+Outstate+Room.Board+PhD+Expend+Grad.Rate,data = train_data)
coef(regfit.full,9)
BIC_model = lm(Apps~Accept+Enroll+Top10perc+Top25perc+F.Undergrad+Outstate+Room.Board+Expend+Grad.Rate, data=train_data)
BIC_test_error = mean((Apps-predict(BIC_model,College))[-train]^2)
BIC_train_error = mean((Apps-predict(BIC_model,College))[train]^2)
CP_test_error = mean((Apps-predict(CP_model,College))[-train]^2)
CP_train_error = mean((Apps-predict(CP_model,College))[train]^2)
BIC_train_error
BIC_test_error
CP_test_error
CP_train_error
x=model.matrix(Apps~.,College)[,-1]
y=College$Apps
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
bestlam=cv.out$lambda.min
ridge.pred = predict(ridge.mod,s=bestlam,newx=x[-train,])
ridge.pred_train = predict(ridge.mod,s=bestlam,newx=x[train,])
ridge_train_error = mean((ridge.pred_train-y[train])^2)
ridge.pred_test = predict(ridge.mod, s=bestlam, newx=x[-train,])
ridge_test_error = mean((ridge.pred_test-y[-train])^2)
ridge_train_error
ridge_test_error
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
test_mse
train_mse
del(Apps)
Apps
remove(Apps)
library(ISLR)
library(tidyverse)
library(glmnet)
library(SignifReg)
library(leaps)
library(pls)
set.seed(23456)
train = sample(1:nrow(College), size =trunc(0.7* nrow(College)))
train_data = College[train, ]
test_data  = College[-train, ]
Apps = College$Apps
lm.mod =lm(Apps~.,data = train_data)
test_error = mean((Apps-predict(lm.mod,College))[-train]^2)
train_error = mean((Apps-predict(lm.mod,College))[train]^2)
test_error
train_error
regfit.fwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="forward", criterion="p-value", correction="FDR")
summary(regfit.fwd)
regfit.bwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="backward", criterion="p-value", correction="FDR")
summary(regfit.bwd)
forward_test_error = mean((Apps-predict(regfit.fwd,College))[-train]^2)
forward_train_error = mean((Apps-predict(regfit.fwd,College))[train]^2)
forward_train_error
forward_test_error
backward_test_error = mean((Apps-predict(regfit.bwd,College))[-train]^2)
backward_train_error = mean((Apps-predict(regfit.bwd,College))[train]^2)
backward_test_error
backward_train_error
regfit.full=regsubsets(Apps~.,train_data, nvmax=18)
reg.summary=summary(regfit.full)
par(mfrow=c(1,2))
plot(reg.summary$cp, xlab="Number of Variables",ylab="Cp",type='l')
CP_variables = which.min(reg.summary$cp)
points(12,reg.summary$cp[12],col="red",cex=2,pch=20)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
BIC_variables = which.min(reg.summary$bic)
points(9,reg.summary$bic[9],col="red",cex=2,pch=20)
plot(regfit.full,scale="bic")
plot(regfit.full, scale ='Cp')
CP_variables
BIC_variables
coef(regfit.full,12)
CP_model = lm(Apps~Private+Accept+Enroll+Top10perc+Top25perc+F.Undergrad+P.Undergrad+Outstate+Room.Board+PhD+Expend+Grad.Rate,data = train_data)
coef(regfit.full,9)
BIC_model = lm(Apps~Accept+Enroll+Top10perc+Top25perc+F.Undergrad+Outstate+Room.Board+Expend+Grad.Rate, data=train_data)
BIC_test_error = mean((Apps-predict(BIC_model,College))[-train]^2)
BIC_train_error = mean((Apps-predict(BIC_model,College))[train]^2)
CP_test_error = mean((Apps-predict(CP_model,College))[-train]^2)
CP_train_error = mean((Apps-predict(CP_model,College))[train]^2)
BIC_train_error
BIC_test_error
CP_test_error
CP_train_error
x=model.matrix(Apps~.,College)[,-1]
y=College$Apps
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
bestlam=cv.out$lambda.min
ridge.pred = predict(ridge.mod,s=bestlam,newx=x[-train,])
ridge.pred_train = predict(ridge.mod,s=bestlam,newx=x[train,])
ridge_train_error = mean((ridge.pred_train-y[train])^2)
ridge.pred_test = predict(ridge.mod, s=bestlam, newx=x[-train,])
ridge_test_error = mean((ridge.pred_test-y[-train])^2)
ridge_train_error
ridge_test_error
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
test_mse
train_mse
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
remove(Apps)
library(ISLR)
library(tidyverse)
library(glmnet)
library(SignifReg)
library(leaps)
library(pls)
set.seed(23456)
train = sample(1:nrow(College), size =trunc(0.7* nrow(College)))
train_data = College[train, ]
test_data  = College[-train, ]
lm.mod =lm(Apps~.,data = train_data)
test_error = mean((Apps-predict(lm.mod,College))[-train]^2)
train_error = mean((Apps-predict(lm.mod,College))[train]^2)
test_error
train_error
regfit.fwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="forward", criterion="p-value", correction="FDR")
summary(regfit.fwd)
regfit.bwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="backward", criterion="p-value", correction="FDR")
summary(regfit.bwd)
forward_test_error = mean((Apps-predict(regfit.fwd,College))[-train]^2)
forward_train_error = mean((Apps-predict(regfit.fwd,College))[train]^2)
forward_train_error
forward_test_error
backward_test_error = mean((Apps-predict(regfit.bwd,College))[-train]^2)
backward_train_error = mean((Apps-predict(regfit.bwd,College))[train]^2)
backward_test_error
backward_train_error
regfit.full=regsubsets(Apps~.,train_data, nvmax=18)
reg.summary=summary(regfit.full)
par(mfrow=c(1,2))
plot(reg.summary$cp, xlab="Number of Variables",ylab="Cp",type='l')
CP_variables = which.min(reg.summary$cp)
points(12,reg.summary$cp[12],col="red",cex=2,pch=20)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
BIC_variables = which.min(reg.summary$bic)
points(9,reg.summary$bic[9],col="red",cex=2,pch=20)
plot(regfit.full,scale="bic")
plot(regfit.full, scale ='Cp')
CP_variables
BIC_variables
coef(regfit.full,12)
CP_model = lm(Apps~Private+Accept+Enroll+Top10perc+Top25perc+F.Undergrad+P.Undergrad+Outstate+Room.Board+PhD+Expend+Grad.Rate,data = train_data)
coef(regfit.full,9)
BIC_model = lm(Apps~Accept+Enroll+Top10perc+Top25perc+F.Undergrad+Outstate+Room.Board+Expend+Grad.Rate, data=train_data)
BIC_test_error = mean((Apps-predict(BIC_model,College))[-train]^2)
BIC_train_error = mean((Apps-predict(BIC_model,College))[train]^2)
CP_test_error = mean((Apps-predict(CP_model,College))[-train]^2)
CP_train_error = mean((Apps-predict(CP_model,College))[train]^2)
BIC_train_error
BIC_test_error
CP_test_error
CP_train_error
x=model.matrix(Apps~.,College)[,-1]
y=College$Apps
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
bestlam=cv.out$lambda.min
ridge.pred = predict(ridge.mod,s=bestlam,newx=x[-train,])
ridge.pred_train = predict(ridge.mod,s=bestlam,newx=x[train,])
ridge_train_error = mean((ridge.pred_train-y[train])^2)
ridge.pred_test = predict(ridge.mod, s=bestlam, newx=x[-train,])
ridge_test_error = mean((ridge.pred_test-y[-train])^2)
ridge_train_error
ridge_test_error
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
test_mse
train_mse
Apps= College$Apps
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
library(ISLR)
library(tidyverse)
library(glmnet)
library(SignifReg)
library(leaps)
library(pls)
set.seed(23456)
train = sample(1:nrow(College), size =trunc(0.7* nrow(College)))
train_data = College[train, ]
test_data  = College[-train, ]
Apps=College$Apps
lm.mod =lm(Apps~.,data = train_data)
test_error = mean((Apps-predict(lm.mod,College))[-train]^2)
train_error = mean((Apps-predict(lm.mod,College))[train]^2)
test_error
train_error
regfit.fwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="forward", criterion="p-value", correction="FDR")
summary(regfit.fwd)
regfit.bwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="backward", criterion="p-value", correction="FDR")
summary(regfit.bwd)
forward_test_error = mean((Apps-predict(regfit.fwd,College))[-train]^2)
forward_train_error = mean((Apps-predict(regfit.fwd,College))[train]^2)
forward_train_error
forward_test_error
backward_test_error = mean((Apps-predict(regfit.bwd,College))[-train]^2)
backward_train_error = mean((Apps-predict(regfit.bwd,College))[train]^2)
backward_test_error
backward_train_error
regfit.full=regsubsets(Apps~.,train_data, nvmax=18)
reg.summary=summary(regfit.full)
par(mfrow=c(1,2))
plot(reg.summary$cp, xlab="Number of Variables",ylab="Cp",type='l')
CP_variables = which.min(reg.summary$cp)
points(12,reg.summary$cp[12],col="red",cex=2,pch=20)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
BIC_variables = which.min(reg.summary$bic)
points(9,reg.summary$bic[9],col="red",cex=2,pch=20)
plot(regfit.full,scale="bic")
plot(regfit.full, scale ='Cp')
CP_variables
BIC_variables
coef(regfit.full,12)
CP_model = lm(Apps~Private+Accept+Enroll+Top10perc+Top25perc+F.Undergrad+P.Undergrad+Outstate+Room.Board+PhD+Expend+Grad.Rate,data = train_data)
coef(regfit.full,9)
BIC_model = lm(Apps~Accept+Enroll+Top10perc+Top25perc+F.Undergrad+Outstate+Room.Board+Expend+Grad.Rate, data=train_data)
BIC_test_error = mean((Apps-predict(BIC_model,College))[-train]^2)
BIC_train_error = mean((Apps-predict(BIC_model,College))[train]^2)
CP_test_error = mean((Apps-predict(CP_model,College))[-train]^2)
CP_train_error = mean((Apps-predict(CP_model,College))[train]^2)
BIC_train_error
BIC_test_error
CP_test_error
CP_train_error
x=model.matrix(Apps~.,College)[,-1]
y=College$Apps
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
bestlam=cv.out$lambda.min
ridge.pred = predict(ridge.mod,s=bestlam,newx=x[-train,])
ridge.pred_train = predict(ridge.mod,s=bestlam,newx=x[train,])
ridge_train_error = mean((ridge.pred_train-y[train])^2)
ridge.pred_test = predict(ridge.mod, s=bestlam, newx=x[-train,])
ridge_test_error = mean((ridge.pred_test-y[-train])^2)
ridge_train_error
ridge_test_error
remove(Apps)
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
test_mse
train_mse
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
remove(Apps)
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
Apps=College$Apps
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
remove(Apps)
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
library(ISLR)
library(tidyverse)
library(glmnet)
library(SignifReg)
library(leaps)
library(pls)
set.seed(23456)
train = sample(1:nrow(College), size =trunc(0.7* nrow(College)))
train_data = College[train, ]
test_data  = College[-train, ]
Apps=College$Apps
lm.mod =lm(Apps~.,data = train_data)
test_error = mean((Apps-predict(lm.mod,College))[-train]^2)
train_error = mean((Apps-predict(lm.mod,College))[train]^2)
test_error
train_error
regfit.fwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="forward", criterion="p-value", correction="FDR")
summary(regfit.fwd)
regfit.bwd = SignifReg(scope=Apps~.,data= as.data.frame(train_data),alpha=0.05, direction="backward", criterion="p-value", correction="FDR")
summary(regfit.bwd)
forward_test_error = mean((Apps-predict(regfit.fwd,College))[-train]^2)
forward_train_error = mean((Apps-predict(regfit.fwd,College))[train]^2)
forward_train_error
forward_test_error
backward_test_error = mean((Apps-predict(regfit.bwd,College))[-train]^2)
backward_train_error = mean((Apps-predict(regfit.bwd,College))[train]^2)
backward_test_error
backward_train_error
regfit.full=regsubsets(Apps~.,train_data, nvmax=18)
reg.summary=summary(regfit.full)
par(mfrow=c(1,2))
plot(reg.summary$cp, xlab="Number of Variables",ylab="Cp",type='l')
CP_variables = which.min(reg.summary$cp)
points(12,reg.summary$cp[12],col="red",cex=2,pch=20)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
BIC_variables = which.min(reg.summary$bic)
points(9,reg.summary$bic[9],col="red",cex=2,pch=20)
plot(regfit.full,scale="bic")
plot(regfit.full, scale ='Cp')
CP_variables
BIC_variables
coef(regfit.full,12)
CP_model = lm(Apps~Private+Accept+Enroll+Top10perc+Top25perc+F.Undergrad+P.Undergrad+Outstate+Room.Board+PhD+Expend+Grad.Rate,data = train_data)
coef(regfit.full,9)
BIC_model = lm(Apps~Accept+Enroll+Top10perc+Top25perc+F.Undergrad+Outstate+Room.Board+Expend+Grad.Rate, data=train_data)
BIC_test_error = mean((Apps-predict(BIC_model,College))[-train]^2)
BIC_train_error = mean((Apps-predict(BIC_model,College))[train]^2)
CP_test_error = mean((Apps-predict(CP_model,College))[-train]^2)
CP_train_error = mean((Apps-predict(CP_model,College))[train]^2)
BIC_train_error
BIC_test_error
CP_test_error
CP_train_error
x=model.matrix(Apps~.,College)[,-1]
y=College$Apps
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
bestlam=cv.out$lambda.min
ridge.pred = predict(ridge.mod,s=bestlam,newx=x[-train,])
ridge.pred_train = predict(ridge.mod,s=bestlam,newx=x[train,])
ridge_train_error = mean((ridge.pred_train-y[train])^2)
ridge.pred_test = predict(ridge.mod, s=bestlam, newx=x[-train,])
ridge_test_error = mean((ridge.pred_test-y[-train])^2)
ridge_train_error
ridge_test_error
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid,thresh=1e-12)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[-train,])
lasso.pred_train=predict(lasso.mod,s=bestlam,newx=x[train,])
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)
laso_test_error = mean((lasso.pred-y[-train])^2)
laso_train_error = mean((lasso.pred_train-y[train])^2)
laso_test_error
laso_train_error
lasso.coef[1:18,]
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
test_mse
train_mse
test_error/test_mse
laso_test_error/test_mse
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
1 - test_error/test_mse
1 - lasso_test_error/test_mse
test_mse = mean((mean(Apps[train])-Apps[-train])^2)
train_mse =  mean((mean(Apps[train])-Apps[train])^2)
1 - test_error/test_mse
1 - laso_test_error/test_mse
1 - CP_test_error/test_mse
1 - BIC_test_error/test_mse
1 - forward_test_error/test_mse
1 - backward_test_error/test_mse
1 - ridge_test_error/test_mse
1 - 696000/test_mse
cleaned_data %>% group_by(category_id) %>% summarise(sum(as.numeric(views)))
library(tidyverse)
library(tidyverse)
library(GGally)
us_data = read.csv('USVideos.csv')
us_data <- us_data[!(us_data$video_error_or_removed == "True" || us_data$comments_disabled == TRUE),]
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
ggplot(us_data) + aes(x = reorder(us_data$category_id, as.numeric(-us_data$views), sum), y = us_data$views, label= views, fill = factor(us_data$category_id)) + geom_bar(stat = "identity") + scale_x_discrete(name = "category id",
labels = scales::comma) + scale_y_continuous(name = "# of Views") + labs(title = "Plot of video category vs number of views of US") + scale_fill_discrete(name = "Category ID")
cleaned_data = subset(us_data, select = c('trending_date', 'title', 'channel_title', 'category_id', 'publish_time', 'tags', 'views', 'likes', 'dislikes', 'comment_count'))
ggcorr(cleaned_data, palette = "RdBu", label = TRUE)
cleaned_data %>% group_by(category_id) %>% summarise(sum(as.numeric(views)))
us_data = read.csv('USVideos.csv')
setwd("~/Downloads/STATS-415-Final-Project-")
library(tidyverse)
library(GGally)
us_data = read.csv('USVideos.csv')
us_data <- us_data[!(us_data$video_error_or_removed == "True" || us_data$comments_disabled == TRUE),]
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
ggplot(us_data) + aes(x = reorder(us_data$category_id, as.numeric(-us_data$views), sum), y = us_data$views, label= views, fill = factor(us_data$category_id)) + geom_bar(stat = "identity") + scale_x_discrete(name = "category id",
labels = scales::comma) + scale_y_continuous(name = "# of Views") + labs(title = "Plot of video category vs number of views of US") + scale_fill_discrete(name = "Category ID")
cleaned_data = subset(us_data, select = c('trending_date', 'title', 'channel_title', 'category_id', 'publish_time', 'tags', 'views', 'likes', 'dislikes', 'comment_count'))
ggcorr(cleaned_data, palette = "RdBu", label = TRUE)
cleaned_data %>% group_by(category_id) %>% summarise(sum(as.numeric(views)))
us_cat_json <- fromJSON("US_category_id.json")
library(jsonlite)
us_cat_json <- fromJSON("US_category_id.json")
US_category <-  as.data.frame(cbind(us_cat_json[["items"]][["id"]], us_cat_json[["items"]][["snippet"]][["title"]]))
names(US_category) <- c("category_id","category_title")
us_data <- merge(x = us_data, y = US_category, by = "category_id", all = "TRUE")
us_data
View(us_data)
cleaned_data <- merge(x = cleaned_data, y = US_category, by = "category_id", all = "TRUE")
cleaned_data
ggplot(cleaned_data) + aes(x = reorder(cleaned_data$category_id, as.numeric(-cleaned_data$views), sum), y = cleaned_data$views, label= views, fill = factor(cleaned_data$category_title)) + geom_bar(stat = "identity") + scale_x_discrete(name = "category title",
labels = scales::comma) + scale_y_continuous(name = "# of Views") + labs(title = "Plot of video category vs number of views of US") + scale_fill_discrete(name = "Category ID")
